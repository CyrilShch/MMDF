{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FuseGAN_without_perceptual_loss.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfgdcRBnQT-u",
        "colab_type": "text"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "641FIu2HQSze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Detect if we are in Google Colaboratory\n",
        "# try:\n",
        "#     import google.colab\n",
        "#     IN_COLAB = True\n",
        "# except ImportError:\n",
        "#     IN_COLAB = False\n",
        "\n",
        "# from pathlib import Path\n",
        "# # Determine the locations of auxiliary libraries and datasets.\n",
        "# # `AUX_DATA_ROOT` is where 'notmnist.py', 'animation.py' and 'tiny-imagenet-2020.zip' are.\n",
        "# if IN_COLAB:\n",
        "#     google.colab.drive.mount(\"/content/drive\")\n",
        "    \n",
        "#     # Change this if you created the shortcut in a different location\n",
        "#     AUX_DATA_ROOT = Path(\"/content/drive/My Drive/\")\n",
        "    \n",
        "#     assert AUX_DATA_ROOT.is_dir(), \"Have you forgotten to 'Add a shortcut to Drive'?\"\n",
        "    \n",
        "#     import sys\n",
        "#     sys.path.insert(0, str(AUX_DATA_ROOT))\n",
        "# else:\n",
        "#     AUX_DATA_ROOT = Path(\".\")\n",
        "\n",
        "# # unzip the data\n",
        "# ![ ! -d \"Data\" ] && unzip -q \"{AUX_DATA_ROOT / 'cropped_data_720x720'}\"\n",
        "# ![ ! -d \"Ground_truth\" ] && unzip -q \"{AUX_DATA_ROOT / 'cropped_gt_720x720'}\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfJ54uGfQW50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "def get_idx_and_num_samples(root):\n",
        "    data = [int(file.split(\"_\")[0]) for files in os.walk(root) for file in files[2]]\n",
        "    counter = dict(Counter(data))\n",
        "\n",
        "    n = [key for key, _ in counter.items()]\n",
        "    count = [value for _, value in counter.items()]\n",
        "\n",
        "    return n, count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Djsu9o2QZGU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get indexes and number of samples for each example\n",
        "\n",
        "root = '/content/content/cropped_data_720x720'\n",
        "n, count = get_idx_and_num_samples(root)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XL2NKEnQzSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## to remove 3, 4 and 5 samples\n",
        "\n",
        "# for ind, number in zip(n, count):\n",
        "#     if number == 3:\n",
        "#         os.remove(f\"/content/content/cropped_data/{ind}_3.png\")\n",
        "\n",
        "#     if number == 4:\n",
        "#         os.remove(f\"/content/content/cropped_data/{ind}_3.png\")\n",
        "#         os.remove(f\"/content/content/cropped_data/{ind}_4.png\")\n",
        "\n",
        "#     if number == 5:\n",
        "#         os.remove(f\"/content/content/cropped_data/{ind}_3.png\")\n",
        "#         os.remove(f\"/content/content/cropped_data/{ind}_4.png\")\n",
        "#         os.remove(f\"/content/content/cropped_data/{ind}_5.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pd7x0ubEiT6c",
        "colab_type": "text"
      },
      "source": [
        "# Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH6CICAFhPUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### ================== GENERATOR============================ ####\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "class DenseBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    DenseNet\n",
        "    \"\"\"\n",
        "    def __init__(self,channels,beta = 0.5):\n",
        "        super(DenseBlock,self).__init__()\n",
        "        self.beta = beta\n",
        "        self.conv_module1 = nn.Sequential(\n",
        "                nn.Conv2d(channels,channels, 3, 1, padding=1),\n",
        "                nn.LeakyReLU(inplace=True)\n",
        "                )\n",
        "        self.conv_module2 = nn.Sequential(\n",
        "                nn.Conv2d(channels,channels, 3, 1, padding=1),\n",
        "                nn.LeakyReLU(inplace=True)\n",
        "                )\n",
        "        self.conv_module3 = nn.Sequential(\n",
        "                nn.Conv2d(channels,channels, 3, 1, padding=1),\n",
        "                nn.LeakyReLU(inplace=True)\n",
        "                )\n",
        "        self.conv_module4 = nn.Sequential(\n",
        "                nn.Conv2d(channels,channels, 3, 1, padding=1),\n",
        "                nn.LeakyReLU(inplace=True)\n",
        "                )\n",
        "        self.last_conv = nn.Conv2d(channels, channels, 3, 1, padding = 1) \n",
        "\n",
        "    def forward(self, x): #three layer\n",
        "        module1_out = self.conv_module1(x)\n",
        "        module1_out_temp = x + module1_out\n",
        "        module2_out = self.conv_module2(module1_out_temp)\n",
        "        module2_out_temp = x + module1_out_temp + module2_out\n",
        "        module4_out_temp = x + module1_out_temp + module2_out_temp\n",
        "        last_conv = self.last_conv(module4_out_temp)\n",
        "        out = x + last_conv * self.beta\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Light(nn.Module):\n",
        "\n",
        "    \"\"\"\n",
        "    Denseblock,Unet\n",
        "    \"\"\"\n",
        "    def __init__(self, in_c, out_c, residual_beta = 0.5):\n",
        "        \"\"\"\n",
        "        in_c : input channels\n",
        "        out_c: output channels\n",
        "        \"\"\"\n",
        "        super(Light,self).__init__()\n",
        "        self.residual_beta = residual_beta\n",
        "\n",
        "        self.inconv = nn.Sequential(\n",
        "            nn.Conv2d(in_c, 64, 9, 1, padding=4),\n",
        "            nn.PReLU()\n",
        "        )\n",
        "        self.down1 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, 3, stride = 1, padding = 1),\n",
        "            nn.PReLU(),\n",
        "            nn.Sequential(*[DenseBlock(64, beta = residual_beta) for _ in range(2)])\n",
        "        )\n",
        "        self.down2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 3, stride = 1, padding = 1),\n",
        "            nn.PReLU(),\n",
        "            nn.Sequential(*[DenseBlock(128, beta = residual_beta) for _ in range(2)])\n",
        "\n",
        "        )\n",
        "        self.down3 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, 3, stride = 1, padding = 1),\n",
        "            nn.PReLU(),\n",
        "            nn.Sequential(*[DenseBlock(256, beta = residual_beta) for _ in range(2)])\n",
        "        )\n",
        "        self.bottom = nn.Sequential(\n",
        "            nn.Conv2d(256, 512, 3, 1 ,padding = 1),\n",
        "            nn.PReLU(),\n",
        "            nn.Conv2d(512, 512, 3, stride = 1, padding = 1),\n",
        "            nn.PReLU(),\n",
        "            nn.Conv2d(512, 256, 3, 1, padding = 1),\n",
        "            nn.PReLU()\n",
        "        )\n",
        "        self.up1 = nn.Sequential(\n",
        "            nn.Conv2d(512, 256, 3, padding = 1),\n",
        "            nn.PReLU(),\n",
        "            nn.Sequential(*[DenseBlock(256 ,beta = residual_beta) for _ in range(2)]),\n",
        "            nn.Conv2d(256, 128, 3, padding = 1),\n",
        "            nn.PReLU()\n",
        "        )\n",
        "        self.up2 = nn.Sequential(\n",
        "            nn.Conv2d(256, 128, 3, padding = 1),\n",
        "            nn.PReLU(),\n",
        "            nn.Sequential(*[DenseBlock(128,beta = residual_beta) for _ in range(2)]),\n",
        "            nn.Conv2d(128, 64, 3, padding = 1),\n",
        "            nn.PReLU()\n",
        "        )\n",
        "        self.up3 = nn.Sequential(\n",
        "            nn.Conv2d(128, 64, 3, padding = 1),\n",
        "            nn.PReLU(),\n",
        "            nn.Sequential(*[DenseBlock(64,beta = residual_beta) for _ in range(2)]),\n",
        "            nn.Conv2d(64, 64, 3, padding = 1),\n",
        "            nn.PReLU()\n",
        "        )\n",
        "        self.out = nn.Conv2d(64, out_c, 9, 1, padding = 4)\n",
        "\n",
        "    def forward(self,x):\n",
        "        cin = self.inconv(x)\n",
        "        down1 = self.down1(cin)\n",
        "        downsample1 = F.avg_pool2d(down1, kernel_size = 2, stride = 2)\n",
        "        down2 = self.down2(downsample1)\n",
        "        downsample2 = F.avg_pool2d(down2, kernel_size = 2, stride = 2)\n",
        "        down3 = self.down3(downsample2)\n",
        "        downsample3 = F.avg_pool2d(down3, kernel_size = 2, stride = 2)\n",
        "\n",
        "        bottom = self.bottom(downsample3)\n",
        "\n",
        "        upsample1 = F.interpolate(bottom, scale_factor = 2)\n",
        "\n",
        "        cat1 = torch.cat([down3, upsample1], dim = 1)\n",
        "        up1 = self.up1(cat1)\n",
        "        upsample2 = F.interpolate(up1, scale_factor = 2)\n",
        "        cat2 = torch.cat([down2, upsample2],dim = 1)\n",
        "        up2 = self.up2(cat2)\n",
        "        upsample3 = F.interpolate(up2, scale_factor = 2)\n",
        "        cat3 = torch.cat([down1, upsample3], dim = 1)\n",
        "        up3 = self.up3(cat3)\n",
        "        out = self.out(up3)\n",
        "        out = (torch.tanh(out) + 1) / 2\n",
        "\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XARHmcs0iXQh",
        "colab_type": "text"
      },
      "source": [
        "# Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vviXSPyoiWza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "class DiscriminatorPatch64(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DiscriminatorPatch64, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.MaxPool2d(kernel_size=(4, 4), stride=(4, 4)),\n",
        "\n",
        "            nn.Conv2d(512, 1, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.net(x)\n",
        "        output_shape = (output.size(0), output.size(2), output.size(3))\n",
        "        final_output = torch.sigmoid(output.view(output_shape))\n",
        "        \n",
        "        return final_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_D0xq7hP2u_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class microDataset(Dataset):\n",
        "    def __init__(self, img_dir, gt_dir, n, transform=None):\n",
        "        self.n = n\n",
        "        self.img_dir = img_dir\n",
        "        self.gt_dir = gt_dir\n",
        "        self.img = sorted(next(os.walk(self.img_dir))[2])\n",
        "        self.gt = sorted(next(os.walk(self.gt_dir))[2])\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.gt)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img1 = Image.open(open(os.path.join(self.img_dir, f\"{self.n[idx]}_1.png\"), 'rb'))\n",
        "        img2 = Image.open(open(os.path.join(self.img_dir,  f\"{self.n[idx]}_2.png\"), 'rb'))\n",
        "        ground_truth = Image.open(open(os.path.join(self.gt_dir, f\"{self.n[idx]}_gt.png\"), 'rb'))\n",
        "\n",
        "        seed = np.random.randint(666)\n",
        "\n",
        "        random.seed(seed)\n",
        "        img1 = self.transform(img1)\n",
        "\n",
        "        random.seed(seed)\n",
        "        img2 = self.transform(img2)\n",
        "\n",
        "        random.seed(seed)\n",
        "        ground_truth = self.transform(ground_truth)\n",
        "\n",
        "        \n",
        "        return img1, img2, ground_truth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOpvF603P_gH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_transform = transforms.ToTensor()\n",
        "train_dataset = microDataset('/content/content/cropped_data_720x720', '/content/content/cropped_gt_720x720', n, transform=data_transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = 1, shuffle=True, pin_memory=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejkrAVPfrPyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gan_train(epochs, dataset, batch_size, optim_disc, optim_gen, discriminator, generator, scheduler_optim_discriminator, scheduler_optim_generator, exp_name = 'my GAN', flag_gp=False):\n",
        "    \n",
        "    writer = SummaryWriter(f'logs/{exp_name}')\n",
        "    losses_D_hist = []\n",
        "    losses_G_hist = []\n",
        "  \n",
        "    for epoch in range(epochs):\n",
        "      \n",
        "        \"Doesn't improve the results\"\n",
        "        if epoch == 100:\n",
        "           batch_size *= 2\n",
        "           \n",
        "        # Train discriminator\n",
        "        discriminator_running_loss = 0.0\n",
        "        total = 0\n",
        "\n",
        "        # Dataloader\n",
        "        loader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, shuffle=True, pin_memory=True)\n",
        "\n",
        "        for batch_idx, (img1, img2, target) in enumerate(loader):\n",
        "\n",
        "            real_data1, real_data2, target = Variable(img1.cuda()), Variable(img2.cuda()), Variable(target.cuda())\n",
        "            mask1 = torch.ones((1, 1, 720, 720)).cuda()\n",
        "            mask2 = torch.ones((1, 1, 720, 720)).cuda()\n",
        "\n",
        "            cat_data = torch.cat((real_data1, real_data2, mask1, mask2), dim=1)\n",
        "\n",
        "            # for _ in range(3):\n",
        "            optim_disc.zero_grad()\n",
        "            optim_gen.zero_grad()\n",
        "            total += batch_size\n",
        "            fake_data = generator(cat_data)\n",
        "\n",
        "            disc_loss = nn.BCELoss()(discriminator(target), torch.ones(discriminator(target).shape).cuda()) + nn.BCELoss()(discriminator(fake_data), torch.zeros(discriminator(fake_data).shape).cuda())\n",
        "            \n",
        "            discriminator_running_loss += disc_loss.item() * batch_size\n",
        "\n",
        "            disc_loss.backward()\n",
        "            optim_disc.step()\n",
        "\n",
        "\n",
        "            # discriminator loss\n",
        "            loss_discriminator = discriminator_running_loss / total\n",
        "            losses_D_hist.append(loss_discriminator)\n",
        "\n",
        "            # update generator\n",
        "            optim_disc.zero_grad()\n",
        "            optim_gen.zero_grad()\n",
        "            fake_data = generator(cat_data)\n",
        "            gen_loss = nn.L1Loss()(fake_data, target) +  0.001 * nn.BCELoss()(discriminator(fake_data), torch.ones(discriminator(fake_data).shape).cuda())\n",
        "            losses_G_hist.append(gen_loss.item())\n",
        "\n",
        "            gen_loss.backward()\n",
        "            optim_gen.step()\n",
        "\n",
        "            # SENDING LOSS TO TENSORBOARD\n",
        "            writer.add_scalar('Discriminator loss', loss_discriminator, global_step = len(losses_D_hist)) \n",
        "\n",
        "            # SENDING LOSS TO TENSORBOARD\n",
        "            writer.add_scalar('Generator loss', gen_loss.item(), global_step = len(losses_G_hist))\n",
        "\n",
        "        # # SENDING IMAGES TO TENSORBOARD\n",
        "        # writer.add_images(\"GAN/Outputs\", torch.FloatTensor(display_images(generator, sharp=True)), epoch+1)\n",
        "        scheduler_optim_generator.step()\n",
        "        scheduler_optim_discriminator.step()\n",
        "        \n",
        "        print(f'epoch : {epoch} | D_loss : {np.round(loss_discriminator, 4)} | G_loss : {np.round(gen_loss.item(), 4)}')\n",
        "        \n",
        "\n",
        "    return losses_D_hist, losses_G_hist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKDlkvSXahSP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython import display\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "### utils\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "exp_name = datetime.now().isoformat(timespec='seconds') + f'GAN'\n",
        "batch_size = 1\n",
        "epochs = 100\n",
        "\n",
        "### models\n",
        "generator = Light(8, 3).cuda()\n",
        "discriminator = DiscriminatorPatch64().cuda()\n",
        "\n",
        "### optimizers\n",
        "optim_discriminator = optim.Adam(discriminator.parameters(), lr = 0.25 * 1e-4, betas=(0.0, 0.9))\n",
        "optim_generator = optim.Adam(generator.parameters(), lr = 0.5 * 1e-4, betas=(0.0, 0.9))\n",
        "\n",
        "### scheduler:  The learning rates of the generator and discriminator are attenuated after each epoch, lr=lr×0.8\n",
        "scheduler_optim_discriminator = torch.optim.lr_scheduler.StepLR(optim_discriminator, 1, 0.8)\n",
        "scheduler_optim_generator = torch.optim.lr_scheduler.StepLR(optim_generator, 1, 0.8)\n",
        "\n",
        "loss_D_naive, loss_G_naive = gan_train(epochs, train_dataset, batch_size, optim_discriminator, optim_generator, discriminator, generator, scheduler_optim_discriminator, scheduler_optim_generator, exp_name = exp_name, flag_gp=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjECGm7fiLYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}